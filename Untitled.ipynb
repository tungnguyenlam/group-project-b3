{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99843ff-0dbd-46ca-a5d6-085ee95da920",
   "metadata": {},
   "source": [
    "Viết lại hết: từ SegDataset -> test với yolov8s -> tìm cách cho hết về cùng dạng -> viết EvalSeg -> test tiếp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b660d97-3a7c-4db1-9e2f-4fd1467104be",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list= [\"Arisa\",\"ARMS\"]\n",
    "batch_size= 1\n",
    "img_size = (256,256)\n",
    "IMAGE_DIR= \"data/Manga109_released_2023_12_07/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a74f07-66fc-41bb-b7d8-f6bbb119446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from SegDataset import MangaBubbleDataset, gather_json\n",
    "import json\n",
    "from torchvision import transforms\n",
    "\n",
    "mask_dir= 'data/MangaSegmentation/jsons_processed'\n",
    "train_json = gather_json(series_list, mask_dir)\n",
    "\n",
    "TRAIN_JSON_FILE = \"train.json\"\n",
    "\n",
    "with open(TRAIN_JSON_FILE, \"w+\") as f:\n",
    "    json.dump(train_json, f, indent=2)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()])\n",
    "    \n",
    "train_set = MangaBubbleDataset(\n",
    "    json_file=TRAIN_JSON_FILE,\n",
    "    img_dir=IMAGE_DIR,\n",
    "    img_size=img_size,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc3c75-6614-4c2c-8f2d-a72dab4043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from EvalSeg import EvalSeg\n",
    "\n",
    "YOLO_MODEL_PATH = 'best.pt'\n",
    "model= YOLO(YOLO_MODEL_PATH)\n",
    "eval_seg = EvalSeg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd93b4-fd78-4079-b75b-15ae67bc392e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "pred_masks = []\n",
    "pred_boxes= []\n",
    "\n",
    "for imgs, gt_masks, gt_bboxes in train_loader:\n",
    "    pred= model.predict(imgs)\n",
    "    for p in pred:\n",
    "        for pb in p.boxes.xyxy.cpu().numpy():  # loop qua từng object\n",
    "            pred_boxes.append(pb)  # mỗi pb là 1D numpy array [4]\n",
    "        if p.masks is not None:\n",
    "            mask_tensor = p.masks.data  # tensor [N,H,W]\n",
    "            binary_mask = mask_tensor > 0.5\n",
    "            pred_masks.append(binary_mask)\n",
    "        else:\n",
    "        # Nếu không có mask, có thể append empty tensor hoặc skip\n",
    "            pred_masks.append(torch.zeros((0, imgs.shape[2], imgs.shape[3]), dtype=torch.bool))\n",
    "\n",
    "eval_seg = EvalSeg()\n",
    "eval_seg.load_info(gt_masks, gt_bboxes, pred_masks, pred_boxes)\n",
    "eval_bboxes = eval_seg.eval_bbox()\n",
    "eval_masks = eval_seg.eval_mask()\n",
    "\n",
    "print(eval_bboxes)\n",
    "print(eval_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a541b57-20a5-460b-aabd-4be6e81c958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd49ca-185d-4c1f-b04c-7a69b94dd9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fc5c1-3c24-4d7b-9919-a5c219b56f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2be2ec-69a8-41e3-9304-f8ba1f0f7c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ac381-8536-4396-82d2-39f035046491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_set.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a01df-52db-4417-99cc-5318e70c94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= train_set.annos_by_id[168]\n",
    "bboxes= []\n",
    "for l in a:\n",
    "    e= l.get('bbox', [])\n",
    "    bboxes.append(e)\n",
    "print(bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4e75d-eb36-49ed-96e1-60346b3db5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a= train_set.annos_by_id\n",
    "bboxes= []\n",
    "masks= []\n",
    "for i in range (1, len(a.keys())+1):\n",
    "    for l in a[i]:\n",
    "        e= l.get('bbox', [])\n",
    "        bboxes.append(e)\n",
    "        m= l.get('segmentation', [])\n",
    "        masks.append(m)\n",
    "print(bboxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e70433-1b7e-452a-80ab-9e1795e0cfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "object_masks= []\n",
    "for seg in masks:\n",
    "    obj_mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "    pts = np.array(seg, dtype=np.float32).reshape(-1,2)\n",
    "    pts[:,0] *= 1\n",
    "    pts[:,1] *= 1\n",
    "    cv2.fillPoly(obj_mask, [pts.astype(np.int32)], 1)\n",
    "    obj_mask= torch.tensor(obj_mask, dtype=torch.bool).unsqueeze(0)\n",
    "    object_masks.append(obj_mask)  # append **1 lần** cho object\n",
    "\n",
    "print(object_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ae962-2c49-4701-98fd-3baf6f073724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "scaled_bboxes=[]\n",
    "object_masks= []\n",
    "scale_x= 0.1\n",
    "scale_y= 0.1\n",
    "img_size= (256, 256)\n",
    "for i in range (1, 3):\n",
    "    for a in train_set.annos_by_id[i]:\n",
    "        e= a.get('bbox', []) \n",
    "        x, y, w, h = map(float, e)\n",
    "        scaled_bboxes.append([x*scale_x, y*scale_y, (x + w)*scale_x, (y + h)*scale_y])\n",
    "\n",
    "        obj_mask = np.zeros((img_size[1], img_size[0]), dtype=np.uint8)\n",
    "        seg= a.get('segmentation', [])\n",
    "        for s in seg:\n",
    "            pts = np.array(s, dtype=np.float32).reshape(-1,2)\n",
    "            pts[:,0] *= scale_x\n",
    "            pts[:,1] *= scale_y\n",
    "            cv2.fillPoly(obj_mask, [pts.astype(np.int32)], 1)\n",
    "            object_masks.append(obj_mask)\n",
    "print(scaled_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b45555-b045-421f-b1ad-e718c192c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(object_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1bb2c-f791-4b38-bfe3-ac146e575ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326e6d9-5d7d-4f1f-acba-e0f2259473cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py13",
   "language": "python",
   "name": "py13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
