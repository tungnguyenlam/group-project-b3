{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd3e6a86",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "ENDWITHS = 'OpenMantra'\n",
                "\n",
                "NOTEBOOK_DIR = os.getcwd()\n",
                "\n",
                "if not NOTEBOOK_DIR.endswith(ENDWITHS):\n",
                "    raise ValueError(f\"Not in correct dir, expect end with {ENDWITHS}, but got {NOTEBOOK_DIR} instead\")\n",
                "\n",
                "BASE_DIR = os.path.abspath(os.path.join(NOTEBOOK_DIR, '..', '..', '..', '..', '..'))\n",
                "print(BASE_DIR)\n",
                "\n",
                "sys.path.insert(0, os.path.join(BASE_DIR, 'code'))\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e552d65c",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
                "\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "elif torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48e38a5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from OpenMantraEvaluator import OpenMantraEvaluator\n",
                "from pipeline.TranslationModels.LLMPerImageTranslator import LLMPerImageTranslator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57d59146",
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "load_dotenv(os.path.abspath(os.path.join(BASE_DIR, '..', '.env')))\n",
                "\n",
                "HF_TOKEN = os.getenv('HF_TOKEN')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9162afd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "OPENMANTRA_ROOT = os.path.join(BASE_DIR, 'data', 'open-mantra-dataset')\n",
                "print(f\"OpenMantra dataset root: {OPENMANTRA_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1b2c3d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
                "\n",
                "evaluator = OpenMantraEvaluator(\n",
                "    openmantra_root=OPENMANTRA_ROOT,\n",
                "    source_lang='text_ja',\n",
                "    target_lang='text_en'\n",
                ")\n",
                "\n",
                "translation_model = LLMPerImageTranslator()\n",
                "translation_model.load_model(device=device, model_name=MODEL_NAME)\n",
                "\n",
                "# Configure predict parameters\n",
                "translation_model.configure(\n",
                "    max_new_tokens=30,\n",
                "    temperature=0.3,\n",
                "    use_batch=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5f6g7h8",
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics = evaluator.evaluate(translation_model, device=device, verbose=True, model_name=MODEL_NAME)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "i9j0k1l2",
            "metadata": {},
            "outputs": [],
            "source": [
                "translation_model.unload_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "m3n4o5p6",
            "metadata": {},
            "outputs": [],
            "source": [
                "for key, value in metrics.items():\n",
                "    print(f\"  {key}: {value:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "py12",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
