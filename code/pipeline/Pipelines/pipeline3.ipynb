{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ENDWITHS = 'Pipelines'\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "\n",
    "if not NOTEBOOK_DIR.endswith(ENDWITHS):\n",
    "    raise ValueError(f\"Not in correct dir, expect end with {ENDWITHS}, but got {NOTEBOOK_DIR} instead\")\n",
    "\n",
    "# Define the base directory relative to the current notebook's location.\n",
    "BASE_DIR = os.path.join(NOTEBOOK_DIR, '..', '..', '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c3ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the project's 'code' directory to the Python path to import custom modules.\n",
    "sys.path.insert(0, os.path.join(BASE_DIR, 'code'))\n",
    "\n",
    "# Import necessary libraries and modules\n",
    "from ultralytics import YOLO\n",
    "from pipeline.OCRModels.MangaOCRModel import MangaOCRModel\n",
    "from pipeline.TranslationModels.ElanMtJaEnTranslator import ElanMtJaEnTranslator\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the trained YOLO model and the example manga image.\n",
    "YOLO_MODEL_PATH = os.path.join(BASE_DIR, 'best.pt')\n",
    "EX_IMG_PATH = os.path.join(BASE_DIR, \"data/Manga109_released_2023_12_07/images/Count3DeKimeteAgeru/005.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418470f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained YOLO model.\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "# Run the prediction on the source image.\n",
    "results = yolo_model.predict(source=EX_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0738cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction returns a list of results; \n",
    "# we are processing a single image, so we take the first element.\n",
    "result = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the original image from BGR (OpenCV's default) to RGB for display.\n",
    "image_rgb = cv2.cvtColor(result.orig_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Extract the raw detection data from the YOLO result object.\n",
    "boxes = result.boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "masks_xy = result.masks.xy              # Segmentation masks as polygon points\n",
    "\n",
    "print(f\"Initial YOLO detection found {len(boxes)} regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase recursion limit to handle complex cases (optional)\n",
    "sys.setrecursionlimit(100)\n",
    "\n",
    "def attempt_split_once(bubble_mask):\n",
    "    \"\"\"\n",
    "    Core function: Attempt to split the mask once.\n",
    "    Returns a list of sub-masks (if split is successful) or [original mask] (if not split).\n",
    "    (This is the refined logic from the original split_connected_bubbles function)\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- HYPERPARAMETERS ---\n",
    "    # Adjusted based on your tuning\n",
    "    MIN_DEFECT_DEPTH = 13         # Minimum depth of a defect to be considered\n",
    "    MAX_ANGLE_DEG = 170           # Maximum angle (allows for flatter connections)\n",
    "    MIN_DIST_BETWEEN_DEFECTS = 20 # Minimum distance to consider defects distinct\n",
    "    \n",
    "    # 1. Basic Checks\n",
    "    contours, _ = cv2.findContours(bubble_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: return [bubble_mask]\n",
    "    \n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    # If the contour is too small (debris), do not attempt to cut.\n",
    "    if cv2.contourArea(contour) < 500: return [bubble_mask] \n",
    "\n",
    "    # 2. Compute Convex Hull & Convexity Defects\n",
    "    try:\n",
    "        hull_indices = cv2.convexHull(contour, returnPoints=False)\n",
    "        if hull_indices is None or len(hull_indices) < 3: return [bubble_mask]\n",
    "        defects = cv2.convexityDefects(contour, hull_indices)\n",
    "    except: return [bubble_mask]\n",
    "\n",
    "    if defects is None: return [bubble_mask]\n",
    "\n",
    "    # 3. Find Potential Cut Candidates\n",
    "    candidates = []\n",
    "    for i in range(defects.shape[0]):\n",
    "        s, e, f, d = defects[i, 0]\n",
    "        depth = d / 256.0\n",
    "        \n",
    "        if depth > MIN_DEFECT_DEPTH:\n",
    "            start = tuple(contour[s][0])\n",
    "            end = tuple(contour[e][0])\n",
    "            far = tuple(contour[f][0])\n",
    "            \n",
    "            # Calculate vectors\n",
    "            v1 = np.array(start) - np.array(far)\n",
    "            v2 = np.array(end) - np.array(far)\n",
    "            n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "            \n",
    "            if n1 == 0 or n2 == 0: continue\n",
    "            \n",
    "            # Calculate angle using Cosine Law\n",
    "            cosine = np.dot(v1, v2) / (n1 * n2)\n",
    "            angle = np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))\n",
    "            \n",
    "            if angle < MAX_ANGLE_DEG:\n",
    "                candidates.append({'point': far, 'depth': depth})\n",
    "\n",
    "    # 4. Clustering (Filter out defects that are too close to each other)\n",
    "    candidates.sort(key=lambda x: x['depth'], reverse=True)\n",
    "    unique_candidates = []\n",
    "    for cand in candidates:\n",
    "        is_distinct = True\n",
    "        for exist in unique_candidates:\n",
    "            dist = np.linalg.norm(np.array(cand['point']) - np.array(exist['point']))\n",
    "            if dist < MIN_DIST_BETWEEN_DEFECTS:\n",
    "                is_distinct = False\n",
    "                break\n",
    "        if is_distinct: unique_candidates.append(cand)\n",
    "\n",
    "    # 5. Execute the Cut\n",
    "    split_mask = bubble_mask.copy()\n",
    "    cut_happened = False\n",
    "    \n",
    "    if len(unique_candidates) >= 2:\n",
    "        # --- LOGIC UPDATE: Shortest Distance Pair ---\n",
    "        # Instead of picking the top 2 deepest points, we pick the pair \n",
    "        # with the shortest Euclidean distance to avoid diagonal cuts.\n",
    "        best_pair = None\n",
    "        min_cut_dist = float('inf')\n",
    "        \n",
    "        # We only check the top 4 deepest candidates to maintain performance/relevance\n",
    "        consider_list = unique_candidates[:4]\n",
    "        \n",
    "        for i in range(len(consider_list)):\n",
    "            for j in range(i + 1, len(consider_list)):\n",
    "                p1 = consider_list[i]['point']\n",
    "                p2 = consider_list[j]['point']\n",
    "                \n",
    "                dist = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "                \n",
    "                if dist < min_cut_dist:\n",
    "                    min_cut_dist = dist\n",
    "                    best_pair = (p1, p2)\n",
    "        \n",
    "        if best_pair:\n",
    "            cv2.line(split_mask, best_pair[0], best_pair[1], 0, 3)\n",
    "            cut_happened = True\n",
    "        \n",
    "    elif len(unique_candidates) == 1:\n",
    "        # Cut from the single defect point towards the centroid\n",
    "        p1 = unique_candidates[0]['point']\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "            # Extend the cut slightly beyond the centroid\n",
    "            dx, dy = cx - p1[0], cy - p1[1]\n",
    "            target = (int(cx + dx*0.5), int(cy + dy*0.5))\n",
    "            cv2.line(split_mask, p1, target, 0, 3)\n",
    "            cut_happened = True\n",
    "\n",
    "    # 6. Return Results\n",
    "    if cut_happened:\n",
    "        new_contours, _ = cv2.findContours(split_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        new_masks = []\n",
    "        for c in new_contours:\n",
    "            # Filter out small debris created by the cut\n",
    "            if cv2.contourArea(c) > 100: \n",
    "                m = np.zeros_like(bubble_mask)\n",
    "                cv2.drawContours(m, [c], -1, 255, -1)\n",
    "                new_masks.append(m)\n",
    "        \n",
    "        # Only return the new masks if we successfully split into > 1 piece\n",
    "        if len(new_masks) > 1:\n",
    "            return new_masks\n",
    "\n",
    "    # Return original if no valid split occurred\n",
    "    return [bubble_mask]\n",
    "\n",
    "# --- MAIN FUNCTION: RECURRENCE ---\n",
    "def split_connected_bubbles(bubble_mask):\n",
    "    \"\"\"\n",
    "    Recursive Wrapper function. It will call attempt_split_once, \n",
    "    if split successfully then call recursively on the child pieces.\n",
    "    \"\"\"\n",
    "    # 1. Try cutting the current mask\n",
    "    initial_results = attempt_split_once(bubble_mask)\n",
    "    \n",
    "    # 2. Stopping condition: If the result is still itself (cannot cut anymore)\n",
    "    # Or the number of pieces returned is 1\n",
    "    if len(initial_results) == 1:\n",
    "        return initial_results\n",
    "    \n",
    "    # 3. Recursive Step:\n",
    "    # If it can be cut into multiple pieces (eg: A and B-C),\n",
    "    # We throw each piece into this function for further processing (B-C -> B and C).\n",
    "    final_bubbles = []\n",
    "    for sub_mask in initial_results:\n",
    "        sub_results = split_connected_bubbles(sub_mask)\n",
    "        final_bubbles.extend(sub_results)\n",
    "        \n",
    "    return final_bubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TOOLS FOR TUNING HYPERPARAMETER (INTERACTIVE) ---\n",
    "# Run this cell to enable drag and drop interface.\n",
    "# After finding 3 numbers you like, go back to Cell 7 and edit it into the official code.\n",
    "\n",
    "# 1. Visualizer function (Updated with SHORTEST DISTANCE logic)\n",
    "def visualize_bubble_split(bubble_mask, min_depth, max_angle, min_dist):\n",
    "\n",
    "    debug_img = cv2.cvtColor(bubble_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    contours, _ = cv2.findContours(bubble_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: return debug_img\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    cv2.drawContours(debug_img, [contour], -1, (0, 255, 255), 2)\n",
    "\n",
    "    try:\n",
    "        hull_indices = cv2.convexHull(contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(contour, hull_indices)\n",
    "    except: return debug_img\n",
    "    \n",
    "    if defects is None: return debug_img\n",
    "\n",
    "    candidates = []\n",
    "    for i in range(defects.shape[0]):\n",
    "        s, e, f, d = defects[i, 0]\n",
    "        depth = d / 256.0\n",
    "        start = tuple(contour[s][0])\n",
    "        end = tuple(contour[e][0])\n",
    "        far = tuple(contour[f][0])\n",
    "\n",
    "        v1 = np.array(start) - np.array(far)\n",
    "        v2 = np.array(end) - np.array(far)\n",
    "        norm1, norm2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "        \n",
    "        angle_deg = 180\n",
    "        if norm1 > 0 and norm2 > 0:\n",
    "            cosine = np.dot(v1, v2) / (norm1 * norm2)\n",
    "            angle_deg = np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))\n",
    "\n",
    "        # Display logic: Green = Pass, Red = Fail\n",
    "        color = (0, 0, 255) \n",
    "        if depth > min_depth and angle_deg < max_angle:\n",
    "            color = (0, 255, 0) \n",
    "            candidates.append({'point': far, 'depth': depth})\n",
    "        \n",
    "        cv2.circle(debug_img, far, 5, color, -1)\n",
    "        # Note the Depth and Angle next to that point\n",
    "        if depth > 10: \n",
    "            cv2.putText(debug_img, f\"{int(depth)}|{int(angle_deg)}\", (far[0]+10, far[1]), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    # Clustering\n",
    "    candidates.sort(key=lambda x: x['depth'], reverse=True)\n",
    "    unique_candidates = []\n",
    "    for cand in candidates:\n",
    "        is_distinct = True\n",
    "        for exist in unique_candidates:\n",
    "            if np.linalg.norm(np.array(cand['point']) - np.array(exist['point'])) < min_dist:\n",
    "                is_distinct = False; break\n",
    "        if is_distinct: unique_candidates.append(cand)\n",
    "\n",
    "    # --- SHORTEST DISTANCE ---\n",
    "    if len(unique_candidates) >= 2:\n",
    "        best_pair = None\n",
    "        min_cut_dist = float('inf')\n",
    "        \n",
    "        # Consider top 4 deepest points\n",
    "        consider_list = unique_candidates[:4]\n",
    "        \n",
    "        for i in range(len(consider_list)):\n",
    "            for j in range(i + 1, len(consider_list)):\n",
    "                p1 = consider_list[i]['point']\n",
    "                p2 = consider_list[j]['point']\n",
    "                \n",
    "                # Calculate distance\n",
    "                dist = np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "                \n",
    "                if dist < min_cut_dist:\n",
    "                    min_cut_dist = dist\n",
    "                    best_pair = (p1, p2)\n",
    "        \n",
    "        if best_pair:\n",
    "            cv2.line(debug_img, best_pair[0], best_pair[1], (255, 0, 0), 3) # Blue Line\n",
    "            cv2.putText(debug_img, \"CUT: SHORTEST\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "            \n",
    "    elif len(unique_candidates) == 1:\n",
    "        p1 = unique_candidates[0][  'point']\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx, cy = int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.line(debug_img, p1, (cx, cy), (255, 0, 0), 3)\n",
    "            cv2.putText(debug_img, \"CUT: CENTROID\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "    return debug_img\n",
    "\n",
    "# 2. Main control function\n",
    "def interactive_tuner(bubble_index, min_depth, max_angle, min_dist):\n",
    "    if len(masks_xy) == 0:\n",
    "        print(\"No masks found from YOLO!\")\n",
    "        return\n",
    "\n",
    "    # Get mask from YOLO result \n",
    "    points = masks_xy[bubble_index]\n",
    "    h, w = result.orig_img.shape[:2]\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [np.array(points, dtype=np.int32)], 255)\n",
    "\n",
    "    # Crop (zoom) into that bubble\n",
    "    x, y, w_b, h_b = cv2.boundingRect(np.array(points, dtype=np.int32))\n",
    "    pad = 30\n",
    "    y1, y2 = max(0, y-pad), min(h, y+h_b+pad)\n",
    "    x1, x2 = max(0, x-pad), min(w, x+w_b+pad)\n",
    "    mask_crop = mask[y1:y2, x1:x2]\n",
    "\n",
    "    # Run visualizer\n",
    "    viz_img = visualize_bubble_split(mask_crop, min_depth, max_angle, min_dist)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(viz_img)\n",
    "    plt.title(f\"Bubble Index: {bubble_index} (Total: {len(masks_xy)})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 3. Initialize interface\n",
    "print(\"--- PARAMETERS TUNER (UPDATED LOGIC) ---\")\n",
    "print(\"1. Drag 'bubble_index' to find the stuck bubble.\")\n",
    "print(\"2. The BLUE line now represents the 'Shortest Distance' cut.\")\n",
    "print(\"3. Remember the 3 numbers and update Cell 7.\")\n",
    "\n",
    "interact(interactive_tuner, \n",
    "         bubble_index=IntSlider(min=0, max=len(masks_xy)-1, step=1, value=0),\n",
    "         min_depth=IntSlider(min=5, max=100, step=1, value=20, description='Depth'),\n",
    "         max_angle=IntSlider(min=10, max=180, step=5, value=145, description='Angle'), # Default updated to 145\n",
    "         min_dist=IntSlider(min=5, max=100, step=5, value=20, description='Dist'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5116e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store the final, individual bubbles after processing.\n",
    "refined_bubble_list = []\n",
    "\n",
    "print(\"Processing raw YOLO masks...\")\n",
    "# Iterate over each detected region from YOLO.\n",
    "for mask_points in masks_xy:\n",
    "    # Create a binary mask from the polygon points.\n",
    "    initial_mask = np.zeros(image_rgb.shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(initial_mask, [np.array(mask_points, dtype=np.int32)], 255)\n",
    "\n",
    "    # Attempt to split the mask into individual bubbles.\n",
    "    split_masks = split_connected_bubbles(initial_mask)\n",
    "\n",
    "    # Process each resulting mask (could be one or more).\n",
    "    for single_mask in split_masks:\n",
    "        contours, _ = cv2.findContours(single_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            continue\n",
    "        \n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        # Calculate the precise bounding box for this individual bubble.\n",
    "        bbox = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Store the refined bubble information.\n",
    "        refined_bubble_list.append({\n",
    "            'mask': single_mask,\n",
    "            'bbox': bbox,\n",
    "            'contour': contour\n",
    "        })\n",
    "\n",
    "# Sort bubbles by reading order (top-to-bottom, then right-to-left for Japanese manga).\n",
    "refined_bubble_list.sort(key=lambda b: (b['bbox'][1], -b['bbox'][0]))\n",
    "\n",
    "print(f\"After splitting, we have {len(refined_bubble_list)} individual bubbles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a Side-by-Side Visualization (Before vs After) ---\n",
    "\n",
    "print(\"Generating comparison visualization...\")\n",
    "\n",
    "# 1. Setup Plot\n",
    "# Calculate aspect ratio\n",
    "ratio = image_rgb.shape[1] / image_rgb.shape[0]\n",
    "width = 20\n",
    "height = width / ratio\n",
    "# Create 2 subplots vertically. We double the height.\n",
    "fig, axes = plt.subplots(2, 1, figsize=(width, height * 2))\n",
    "\n",
    "# =========================================================\n",
    "# PLOT 1: BEFORE Applying Convexity Split (Raw YOLO Output)\n",
    "# =========================================================\n",
    "vis_before = image_rgb.copy()\n",
    "overlay_before = image_rgb.copy()\n",
    "alpha = 0.4\n",
    "\n",
    "# Retrieve raw masks from YOLO result \n",
    "raw_masks_points = result.masks.xy\n",
    "\n",
    "for i, points in enumerate(raw_masks_points):\n",
    "    # Convert points to integer format for OpenCV\n",
    "    contour = np.array(points, dtype=np.int32)\n",
    "    \n",
    "    # 1. Draw Segmentation Mask\n",
    "    color = np.random.randint(50, 255, size=3).tolist()\n",
    "    cv2.drawContours(overlay_before, [contour], -1, color, thickness=cv2.FILLED)\n",
    "    \n",
    "    # 2. Draw Bounding Box (Calculated from mask contour)\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "    axes[0].add_patch(rect)\n",
    "    \n",
    "    # 3. Add ID Label\n",
    "    axes[0].text(x, y - 5, f'Raw: {i}', fontsize=12, color='white',\n",
    "                 bbox=dict(facecolor='red', alpha=0.8, pad=0.5, edgecolor='none'),\n",
    "                 verticalalignment='bottom')\n",
    "\n",
    "# Blend and Display\n",
    "vis_before = cv2.addWeighted(overlay_before, alpha, vis_before, 1 - alpha, 0)\n",
    "axes[0].imshow(vis_before)\n",
    "axes[0].set_title(f\"BEFORE: Raw YOLO Output ({len(raw_masks_points)} bubbles)\", fontsize=18, fontweight='bold', color='red')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# =========================================================\n",
    "# PLOT 2: AFTER Applying Convexity Split (Refined Bubbles)\n",
    "# =========================================================\n",
    "vis_after = image_rgb.copy()\n",
    "overlay_after = image_rgb.copy()\n",
    "\n",
    "for i, bubble in enumerate(refined_bubble_list):\n",
    "    # 1. Draw Segmentation Mask\n",
    "    color = np.random.randint(50, 255, size=3).tolist()\n",
    "    contour = bubble['contour']\n",
    "    cv2.drawContours(overlay_after, [contour], -1, color, thickness=cv2.FILLED)\n",
    "    \n",
    "    # 2. Draw Bounding Box\n",
    "    x, y, w, h = bubble['bbox']\n",
    "    rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='lime', facecolor='none')\n",
    "    axes[1].add_patch(rect)\n",
    "\n",
    "    # 3. Add ID Label\n",
    "    axes[1].text(x, y - 5, f'ID: {i}', fontsize=12, color='black',\n",
    "                 bbox=dict(facecolor='lime', alpha=0.8, pad=0.5, edgecolor='none'),\n",
    "                 verticalalignment='bottom')\n",
    "\n",
    "# Blend and Display\n",
    "vis_after = cv2.addWeighted(overlay_after, alpha, vis_after, 1 - alpha, 0)\n",
    "axes[1].imshow(vis_after)\n",
    "axes[1].set_title(f\"AFTER: Refined with Convexity Split ({len(refined_bubble_list)} bubbles)\", fontsize=18, fontweight='bold', color='green')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=1.0) # Add some padding between plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa47625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load the OCR model.\n",
    "manga_ocr_model = MangaOCRModel()\n",
    "manga_ocr_model.load_model()\n",
    "\n",
    "print(\"\\nRunning OCR on each individual bubble...\")\n",
    "image_rgb_array = np.array(image_rgb)\n",
    "\n",
    "# Iterate through the refined list of bubbles.\n",
    "for i, bubble in enumerate(refined_bubble_list):\n",
    "    x, y, w, h = bubble['bbox']\n",
    "    \n",
    "    # Crop the image using the precise bounding box.\n",
    "    cropped_image = image_rgb_array[y:y+h, x:x+w]\n",
    "    \n",
    "    # Perform OCR on the cropped image.\n",
    "    text = manga_ocr_model.predict(cropped_image)\n",
    "    \n",
    "    # Store the recognized text back into the bubble's dictionary.\n",
    "    bubble['ocr_text'] = text\n",
    "    \n",
    "    print(f\"Bubble ID {i}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d215e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load the translation model.\n",
    "model_trans = ElanMtJaEnTranslator()\n",
    "model_trans.load_model()\n",
    "\n",
    "print(\"\\n--- Translation Results ---\")\n",
    "# Iterate through the bubbles again to translate the OCR'd text.\n",
    "for i, bubble in enumerate(refined_bubble_list):\n",
    "    ocr_text = bubble.get('ocr_text', '')\n",
    "    \n",
    "    if ocr_text.strip():\n",
    "        translated_text = model_trans.predict(ocr_text)\n",
    "        bubble['translated_text'] = translated_text\n",
    "    else:\n",
    "        bubble['translated_text'] = ''\n",
    "\n",
    "# Print the final results for verification.\n",
    "for i, bubble in enumerate(refined_bubble_list):\n",
    "    print(f\"Bbox ID: {i}\")\n",
    "    print(f\"  - OCR: {bubble.get('ocr_text', '')}\")\n",
    "    print(f\"  - Translation: {bubble.get('translated_text', '')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "font_props = fm.FontProperties(family=['Comic Sans MS', 'Chalkboard SE', 'sans-serif'])\n",
    "\n",
    "# 2. Get the actual file path from Matplotlib's font manager\n",
    "FONT_PATH = fm.findfont(font_props)\n",
    "\n",
    "print(f\"Using Font Path: {FONT_PATH}\")\n",
    "\n",
    "def smart_wrap_text(draw, text, font, max_width_px):\n",
    "    \"\"\"\n",
    "    Wraps text based on pixel width without breaking words mid-way \n",
    "    unless the word is wider than the max_width itself.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Check width of current line + new word\n",
    "        test_line = ' '.join(current_line + [word])\n",
    "        w = draw.textbbox((0, 0), test_line, font=font)[2]\n",
    "        \n",
    "        if w <= max_width_px:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            # If the line is not empty, push it and start a new one\n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "                current_line = [word]\n",
    "            else:\n",
    "                # CORNER CASE: The single word is wider than the max_width.\n",
    "                # We strictly must break this word.\n",
    "                # We fallback to character-by-character splitting for just this huge word.\n",
    "                temp_word = \"\"\n",
    "                for char in word:\n",
    "                    if draw.textbbox((0, 0), temp_word + char, font=font)[2] <= max_width_px:\n",
    "                        temp_word += char\n",
    "                    else:\n",
    "                        lines.append(temp_word)\n",
    "                        temp_word = char\n",
    "                current_line = [temp_word]\n",
    "\n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "        \n",
    "    return lines\n",
    "\n",
    "def check_mask_collision(text_mask, bubble_mask_crop):\n",
    "    \"\"\"\n",
    "    Returns True if the text (white pixels in text_mask) \n",
    "    overlaps with the background (black pixels in bubble_mask_crop).\n",
    "    \"\"\"\n",
    "    # In bubble_mask, White = Safe Area, Black = Wall.\n",
    "    # In text_mask, White = Text, Black = Empty.\n",
    "    \n",
    "    # We want to know if Text touches Black area of bubble.\n",
    "    # Invert bubble: White = Wall.\n",
    "    bubble_wall = cv2.bitwise_not(bubble_mask_crop)\n",
    "    \n",
    "    # Intersection: Where Text AND Wall are both white.\n",
    "    overlap = cv2.bitwise_and(text_mask, bubble_wall)\n",
    "    \n",
    "    # If there are any white pixels in overlap, we have a collision.\n",
    "    return cv2.countNonZero(overlap) > 0\n",
    "\n",
    "def fit_text_in_mask(draw, text, font_path, mask, text_color):\n",
    "    \"\"\"\n",
    "    Fits text into the irregular shape of the mask by checking pixel collisions.\n",
    "    It finds the largest font size where the text block fits entirely within the white mask.\n",
    "    \"\"\"\n",
    "    if not text.strip(): return\n",
    "    \n",
    "    # 1. Find contours to determine the center and general bounds\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: return\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    # Calculate Visual Center (Centroid) using Moments\n",
    "    M = cv2.moments(cnt)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        cx, cy = x + w // 2, y + h // 2\n",
    "        \n",
    "    # Crop the mask to the bounding box for efficient processing\n",
    "    mask_crop = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    # Initial Parameters\n",
    "    best_font = None\n",
    "    best_lines = []\n",
    "    best_y_start = 0\n",
    "    \n",
    "    # Heuristic: Start font size roughly based on height, usually 1/2 height is a good upper limit\n",
    "    font_size = min(h, w)\n",
    "    min_font_size = 10 # Readable minimum\n",
    "    \n",
    "    while font_size >= min_font_size:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "        \n",
    "        # We try to wrap text into a box roughly the aspect ratio of the bubble\n",
    "        # This helps squares fit in squares and wide text fit in wide bubbles\n",
    "        target_width = w * 0.9 # Give 10% padding initially\n",
    "        \n",
    "        lines = smart_wrap_text(draw, text, font, target_width)\n",
    "        \n",
    "        # Calculate text block size\n",
    "        text_h = sum([draw.textbbox((0, 0), line, font=font)[3] for line in lines])\n",
    "        text_w = max([draw.textbbox((0, 0), line, font=font)[2] for line in lines]) if lines else 0\n",
    "        \n",
    "        # Quick check: if text block is bigger than bbox, definitely doesn't fit\n",
    "        if text_h > h or text_w > w:\n",
    "            font_size -= 2\n",
    "            continue\n",
    "\n",
    "        # --- PIXEL PERFECT COLLISION CHECK ---\n",
    "        \n",
    "        # Create a temporary binary mask for the text\n",
    "        # Size matches the cropped bubble mask\n",
    "        text_canvas = np.zeros((h, w), dtype=np.uint8)\n",
    "        pil_canvas = Image.fromarray(text_canvas)\n",
    "        canvas_draw = ImageDraw.Draw(pil_canvas)\n",
    "        \n",
    "        # Calculate position to draw text on this temp canvas\n",
    "        # We want the center of the text to align with the center of the mask (cx, cy)\n",
    "        # Convert absolute center (cx, cy) to relative center inside crop\n",
    "        rel_cx = cx - x\n",
    "        rel_cy = cy - y\n",
    "        \n",
    "        curr_y = rel_cy - (text_h / 2)\n",
    "        \n",
    "        for line in lines:\n",
    "            line_w = draw.textbbox((0, 0), line, font=font)[2]\n",
    "            line_h = draw.textbbox((0, 0), line, font=font)[3]\n",
    "            curr_x = rel_cx - (line_w / 2)\n",
    "            \n",
    "            # Draw white text\n",
    "            canvas_draw.text((curr_x, curr_y), line, font=font, fill=255)\n",
    "            curr_y += line_h\n",
    "            \n",
    "        text_mask = np.array(pil_canvas)\n",
    "        \n",
    "        # Check collision\n",
    "        if not check_mask_collision(text_mask, mask_crop):\n",
    "            # NO COLLISION! IT FITS!\n",
    "            best_font = font\n",
    "            best_lines = lines\n",
    "            # Calculate final global start Y\n",
    "            best_y_start = cy - (text_h / 2)\n",
    "            break\n",
    "            \n",
    "        font_size -= 2 # Decrease and try again\n",
    "\n",
    "    # If loop finished without fitting (very rare), use smallest size\n",
    "    if best_font is None:\n",
    "        best_font = ImageFont.truetype(font_path, min_font_size)\n",
    "        best_lines = smart_wrap_text(draw, text, best_font, w)\n",
    "        text_h = sum([draw.textbbox((0, 0), line, font=best_font)[3] for line in best_lines])\n",
    "        best_y_start = cy - (text_h / 2)\n",
    "\n",
    "    # --- DRAW FINAL TEXT ON MAIN IMAGE ---\n",
    "    current_y = best_y_start\n",
    "    for line in best_lines:\n",
    "        line_w = draw.textbbox((0, 0), line, font=best_font)[2]\n",
    "        line_h = draw.textbbox((0, 0), line, font=best_font)[3]\n",
    "        current_x = cx - (line_w / 2)\n",
    "        \n",
    "        draw.text((current_x, current_y), line, font=best_font, fill=text_color)\n",
    "        current_y += line_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLOR = (0, 0, 0) # Black\n",
    "\n",
    "image_final = image_rgb.copy()\n",
    "# Stronger erosion to ensure we clean up the old Japanese text thoroughly\n",
    "erosion_kernel = np.ones((6, 6), np.uint8) \n",
    "\n",
    "# Iterate through the final, complete list of individual bubbles.\n",
    "for bubble in refined_bubble_list:\n",
    "    trans_text = bubble.get('translated_text', '')\n",
    "    if not trans_text.strip():\n",
    "        continue\n",
    "\n",
    "    single_mask = bubble['mask']\n",
    "\n",
    "    # STEP 1: Erode the mask to find the \"Whitening Area\" (remove old text)\n",
    "    # We erode slightly to not overwrite the bubble border\n",
    "    eroded_mask = cv2.erode(single_mask, erosion_kernel, iterations=1)\n",
    "    \n",
    "    # Paint white on the main image to clear old text\n",
    "    contours, _ = cv2.findContours(eroded_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(image_final, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    \n",
    "    # STEP 2: Use the UN-ERODED (Original) mask for text fitting\n",
    "    # This allows the text to go closer to the border if needed, maximizing size.\n",
    "    \n",
    "    pil_image = Image.fromarray(image_final)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    \n",
    "    # Pass the MASK, not the BBox, to the new function\n",
    "    fit_text_in_mask(draw, trans_text, FONT_PATH, single_mask, TEXT_COLOR)\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    image_final = np.array(pil_image)\n",
    "\n",
    "# --- Display the final, typeset image ---\n",
    "ratio = image_final.shape[1] / image_final.shape[0]\n",
    "width = 20\n",
    "height = width / ratio\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width, height))\n",
    "ax.imshow(image_final)\n",
    "ax.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
